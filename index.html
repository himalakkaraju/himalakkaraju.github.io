
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="Hima Lakkaraju" content="">
    <meta name="Hima Lakkaraju" content="">

    <title>Hima Lakkaraju</title>

    <!-- Nunito Sans font -->
    <link href="https://fonts.googleapis.com/css?family=Nunito+Sans" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Patrick+Hand+SC" rel="stylesheet">
    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <!-- Bootstrap theme -->
    <link href="css/bootstrap-theme.min.css" rel="stylesheet">
    <!-- font awesome icons -->
    <link href="css/icon.css" rel="stylesheet">
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="css/ie10-viewport-bug-workaround.css" rel="stylesheet">
    <!-- Overriding personal style -->
    <link href="css/style.css" rel="stylesheet">   
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  <script type="text/javascript">
   function visibility_on(id) {
        var e = document.getElementById(id+"_text");
        if(e.style.display == 'none')
            e.style.display = 'block';
        var e = document.getElementById(id+"_img");
        if(e.style.display == 'none')
            e.style.display = 'block';
   }
   function visibility_off(id) {
        var e = document.getElementById(id+"_text");
        if(e.style.display == 'block')
            e.style.display = 'none';
        var e = document.getElementById(id+"_img");
        if(e.style.display == 'block')
            e.style.display = 'none';
   }
   function toggle_visibility(id) {
       var e = document.getElementById(id+"_text");
       if(e.style.display == 'inline')
          e.style.display = 'block';
       else
          e.style.display = 'inline';
       var e = document.getElementById(id+"_img");
       if(e.style.display == 'inline')
          e.style.display = 'block';
       else
          e.style.display = 'inline';
   }
   function toggle_vis(id) {
       var e = document.getElementById(id);
       if (e.style.display == 'none')
           e.style.display = 'inline';
       else
           e.style.display = 'none';
   }
</script>
    <style>
	  	ul.no-bullets {
  				list-style-type: none;
  				margin: 0;
  				padding: 0;
			       }
    </style>
  </head>

  <body>
    <!-- Fixed navbar -->
    <nav class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">Hima Lakkaraju</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href="#">Home</a></li>
            <li><a href="#news">News</a></li>	    
            <li><a href="#research">Research</a></li>
	    <li><a href="#students">Advising</a></li>
            <li><a href="#teaching">Teaching</a></li>
	    <li><a href="https://himalakkaraju.github.io/openpositions.html">Open Positions</a></li>
            <!--<li><a href="#papers">Service</a></li>-->
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container theme-showcase" role="main">
      <div class="row">
	<div class="col-md-3">
	  <h3>Hima Lakkaraju</h3>
	  <img class="img-thumbnail" src="images/hima-2019.jpg" alt="" style="width:70%"/>
	  <br /><br />
	  <h4>Contact</h4>
	<font size="3"><a href="mailto:hlakkaraju@hbs.edu" class="icon fa-envelope"></a> hlakkaraju@hbs.edu<br />
	<font size="3"><a href="mailto:hlakkaraju@seas.harvard.edu" class="icon fa-envelope"></a> hlakkaraju@seas.harvard.edu<br />
	<br>
	<a href="https://www.google.com/maps/place/Morgan+Hall/@42.3667845,-71.1265611,17z/data=!3m1!4b1!4m6!3m5!1s0x89e37760e21ea9e1:0x741d6b281be359d7!8m2!3d42.3667845!4d-71.1239862!16s%2Fg%2F11cly_200s?entry=ttu" class="icon fa-building"></a> Morgan Hall 491<br />
	<a href="https://www.google.com/maps/place/Science+%26+Engineering+Complex/@42.406037,-71.1219121,17z/data=!3m1!4b1!4m6!3m5!1s0x89e377378cf93c53:0xc17eac62367d9b99!8m2!3d42.4060331!4d-71.1170412!16s%2Fg%2F11pkcgblk0?entry=ttu" class="icon fa-building"></a> Science and Engineering Complex 6.220<br />
	<br><a href="https://twitter.com/hima_lakkaraju" class="icon fa-twitter"></a> @hima_lakkaraju
	<br> <a href="https://github.com/AI4LIFE-GROUP" class="icon fa-github"></a> lvhimabindu<br />	  </font>
	</div>
	
	<div class="col-md-9">
	  <br /><br />
	  <h3></h3>
	  <font size="3">

<p>I am an <font color="#cc0000">Assistant Professor at Harvard University</font> with appointments in the Business School and the Department of Computer Science. Prior to my stint at Harvard, I received my PhD in Computer Science from Stanford University.</p> 
<blockquote style=" padding: 10px; background-color: #eeeeee;"><font size="3">
         <p>My research interests lie within the broad area of <font color="#cc0000">trustworthy machine learning</font>. More specifically, I focus on improving the <font color="#cc0000">interpretability</font>, <font color="#cc0000">fairness</font>,  <font color="#cc0000">privacy</font>, <font color="#cc0000">robustness</font>, and <font color="#cc0000">reasoning</font> capabilities of different kinds of ML models, including large language models and other pre-trained models. 
		 <!-- I am also very interested in improving the interpretability, fairness, robustness, and reasoning capabilities of language models and other large pre-trained models. -->
		 <!-- <p>I develop machine learning tools and techniques which enable human decision makers to make better decisions. -->
		My research addresses the following fundamental questions pertaining to human and algorithmic decision-making:
	</p>
	<ol>
<li> How can we build interpretable and accurate models to assist in human decision-making?
<li> How do we identify and correct underlying biases in both human decisions and model predictions? 
<li> How can we ensure that models and their interpretations are robust to adversarial and privacy attacks? 
<li> How do we train and evaluate models when faced with missing counterfactuals?
</ol>
<p>These questions have far-reaching implications in domains involving high-stakes decisions such as health care, policy, law, and business. <!-- and here is a <a href="./one-pager.pdf">one-pager</a> about my research. -->
<!--My research tackles the above questions by effectively handling the core underlying challenges such as missing counterfactuals and presence of unmeasured confounders.--> 
</p>

	
	</font>
	
</blockquote>
		  <p> I lead the <font color="#cc0000">AI4LIFE</font> research group at Harvard and I recently co-founded the <a href="https://www.trustworthyml.org/">Trustworthy ML Initiative (TrustML)</a> to help lower entry barriers into trustworthy ML and bring together researchers and practitioners working in the field. 
		  My research is being generously supported by <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2008461&HistoricalAwards=false">NSF</a>, <a href="https://research.google/outreach/">Google</a>, <a href="https://ai2050.schmidtsciences.org/fellows/">Schmidt Sciences</a>, <a href="https://openai.com/">OpenAI</a>, <a href="https://www.amazon.science/research-awards/recipients/himabindu-lakkaraju-2020">Amazon</a>, <a href="https://www.jpmorgan.com/technology/artificial-intelligence/research-awards">JP Morgan</a>, <a href="https://research.adobe.com/data-science-research-awards/">Adobe</a>, <a href="https://www.bayer.com/en/">Bayer</a>, <a href="https://datascience.harvard.edu/">Harvard Data Science Initiative</a>, and <a href="https://d3.harvard.edu/">D^3 Insitute at Harvard</a>. 
		  My work has been featured in various major media outlets including the <a href="https://www.nytimes.com/2017/12/20/upshot/algorithms-bail-criminal-justice-system.html">New York Times</a>, <a href="https://time.com/6289953/schumer-ai-regulation-explainability/">TIME magazine</a>, 
	<a href="https://fortune.com/2022/03/22/ai-explainable-radiology-medicine-crisis-eye-on-ai/">Fortune</a>, <a href="http://www.forbes.com/sites/timworstall/2013/09/02/how-to-craft-the-perfect-reddit-posting/">Forbes</a>, <a href="https://www.technologyreview.com/s/603763/how-to-upgrade-judges-with-machine-learning/">MIT Technology Review</a>, and <a href="https://hbr.org/2019/12/the-ai-transparency-paradox">Harvard Business Review</a>. 
		 </p>
		 <p> Please check out my <a href="./HimaCV.pdf">CV</a> for more details about me and my research. </p>
<p>
<font color="#cc0000">NOTE:</font> I am looking for motivated <font color="#cc0000">graduate and undergraduate students and postdocs</font> who are broadly interested in trustworthy machine learning and large pre-trained models. 
	If you are excited about this line of research and would like to work with me, please <a href="javascript:toggle_vis('contact')">read this</a> before contacting me. 
</p>		  <div id="contact" style="display:none"> 
		  <blockquote style=" padding: 10px; background-color: #EEEEEE;"><font size="3">
                  <p>Thank you for your interest in joining my lab! I am currently recruiting undergraduate, masters, and PhD students as well as postdoctoral fellows. </p>
			  <p>If you are interested in a <i>postdoc</i> position, please see <a href="https://himalakkaraju.github.io/openpositions.html">this page</a> for more details and application process. <!--send me an email with your 
 and a brief description of your research interests. Please use the subject line <font color="#cc0000">"Postdoctoral Fellowship Application"</font> in your email. --> </p> 
		  <p>If you are a <i>current or admitted undergraduate or masters or PhD student at Harvard</i>, please send me an email with your CV and a brief description of your research interests. Please use the subject line <font color="#cc0000">"Interested in Collaboration (Harvard Student)"</font> in your email. 
	  	  </p>
		  If you are <i>not (yet!) a student at Harvard and would like to pursue a PhD under my guidance</i>, <font color="#cc0000">please apply to BOTH the following PhD programs and mention my name in your statements and applications</font>: 
		  <ol>
			  <li> <a href="https://gsas.harvard.edu/programs-of-study/all/business-administration">PhD Program in Technology and Operations Management</a> at Harvard Business School. 
			  </li>
			  <li> <a href="https://www.seas.harvard.edu/computer-science/graduate-programs/how-apply">PhD Program in Computer Science</a> at Harvard SEAS.
			  </li>	  
		  </ol>
		  <p> I have few internship positions available for students who are already doing their PhD in the United States. If this is of interest, please send me an email with your CV and a brief description of your research interests. Please use the subject line <font color="#cc0000">"Internship Position (PhD Student)"</font> in your email. 
			  </p> 
		  <p>
		  Unfortunately, I will not be able to respond to any individual emails about admissions to masters or PhD programs. 
	 	  </p>
		  <!--<p> I am also open to research collaborations with students and faculty both within Harvard and elsewhere. If you are interested in collaborating with me and my group, please send me an email with a brief description of your research interests and background. Please do not forget to include a link to your webpage and/or your CV. </p>
	        -->  
		</blockquote>
	          </div>
		  </font>

	  
	</div>
	<font size="3">
      </div>

      <div class="page-header" id="news"><h3>Selected Achievements & News</h3></div>
      <div class="row">
        <div class="col-md-12">
          <ul>
		  <li>Excited to serve as the ethics co-chair for <a href="https://neurips.cc/Conferences/2024">NeurIPS 2024</a></li>
		  <li><a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2238714&HistoricalAwards=false">NSF CAREER Award</a>, 2023</li>
		  <li><a href="https://ai2050.schmidtfutures.com/fellows/">AI2050 Early Career Fellowship</a> by Schmidt Sciences, 2023</li>
		  <li>Named <a href="https://www.nasonline.org/programs/kavli-frontiers-of-science/past-symposia/2023-uskfos.html">Kavli Fellow 2023</a> by National Academy of Sciences</li>
		  <li><a href="https://research.adobe.com/data-science-research-awards/">Adobe Data Science Research Award</a>, 2023</li>
		  <li>Excited to co-organize the first workshop on <a href="https://regulatableml.github.io/">Regulatable ML: Bridging the Gaps between ML Research and Regulations</a> at NeurIPS, 2023.</li>
		  <li>Excited to serve as the tutorial co-chair for WSDM 2024</li>
		  <li>Excited to serve as the sponsorship co-chair for FAccT 2023</li>
		  <li> My <a href="https://www.youtube.com/playlist?list=PLoROMvodv4rPh6wa6PGcHH6vMG9sEIPxL">short course on Explainable AI</a> hosted by Stanford University is now available on Youtube (over 81,000 views) </li>
		  <li> Outstanding Paper Award Honorable Mention, <a href="https://tsrml2022.github.io/">NeurIPS Workshop on Trustworthy and Socially Responsible Machine Learning</a>, 2022 </li>
		  <li> <a href="https://www.jpmorgan.com/technology/artificial-intelligence/research-awards">JP Morgan Faculty Research Award</a>, 2022 </li>
		  <li> Best Paper Award, <a href="https://icml.cc/virtual/2021/workshop/8358">ICML Workshop on Interpretable ML in Healthcare</a>, 2022 </li>
		  <li> Released the first version of <a href="https://open-xai.github.io/">OpenXAI</a>, a light-weight open source library to evaluate and benchmark post hoc explanation methods, 2022 </li>
		  <li> <a href="https://www.amazon.science/research-awards/recipients/himabindu-lakkaraju-2020">Amazon Research Award</a>, 2021 </li>
		  <li> <a href="https://sites.google.com/view/aiforsocialgoodworkshop/2021-projects">Google AI for Social Good Research Award</a>, 2021 </li>
		  <li> Best Paper Runner Up, <a href="https://icml.cc/virtual/2021/workshop/8363">ICML Workshop on Algorithmic Recourse</a>, 2021 </li>
		  <li> <a href="https://research.google/outreach/research-scholar-program/recipients/">Google Research Award</a>, 2020 </li>
		  <li> <a href="https://prizes.fas.harvard.edu/hoopes-prize">Hoopes prize</a> for undergraduate thesis mentoring, Harvard University, 2020 </li>
		  <li> Co-founded <a href="https://www.trustworthyml.org/">Trustworthy ML Initiative</a> to enable easy access to resources on trustworthy ML & to build a community of researchers/practitioners, 2020 </li>
		  <li> Named one of the world's <a href="https://www.innovatorsunder35.com/the-list/himabindu-lakkaraju/">35 innovators under 35 by MIT Tech Review</a>, 2019 </li>
		  <li> Named one of the world's <a href="https://www.vanityfair.com/news/2019/10/future-innovators-index-2019">top innovators to watch by Vanity Fair</a>, 2019 </li>
		  <li> Selected for the prestigious Cowles fellowship by Yale University, 2018 </li>
		  <li> INFORMS Best Data Mining Paper Award, 2017 </li>
		  <li> <a href="https://www.microsoft.com/en-us/research/blog/dissertation-grant-program-winners/">Microsoft Research Dissertation Grant</a>, 2017 </li>
		  <li> Named a <a href="http://risingstars.ece.cmu.edu/himabindu-lakkaraju/">Rising Star in Computer Science</a>, 2016 </li>
		  <li> <a href="https://buildyourfuture.withgoogle.com/programs"> Google Anita Borg Fellowship </a>, 2015 </li>
		  <li> <a href="https://vpge.stanford.edu/fellowships-funding/current-vpge-fellows/all-2013">Stanford Graduate Fellowship</a>, 2013-17 </li>
		  <li> Eminence and Excellence Award, IBM Research, 2012 </li>
		  <li> Research Division Award, IBM Research, 2012 </li>
		  <li> Best Paper Award, <a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611972818.43">SIAM International Conference on Data Mining</a>, 2011 </li> 
          </ul>
        </div>
      </div>
 
      <div class="page-header" id="news"><h3>Upcoming and Recent Talks</h3></div>
      <div class="row">
        <div class="col-md-12">
          <ul>
		  <li><date>11.2024</date> EMNLP Workshop on BlackboxNLP </li>
		  <li><date>10.2024</date> Learning Machines Seminar, Cornell University </li>
		  <li><date>10.2024</date> First Annual Summit on Responsible Computing, AI, and Society, Georgia Tech</li>
		  <li><date>10.2024</date> AI Alignment Workshop, University of Maryland</li>
		  <li><date>09.2024</date> Workshops on AI Regulation, India and Singapore</li>
		  <li><date>04.2024</date> Princeton University Workshop on Understanding in Natural and Artificial Minds</li>
		  <li><date>04.2024</date> Johns Hopkins CS Seminar Series</li>
		  <li> <date>03.2024</date><a href="https://www.sec.gov/"> US Securities and Exchange Commission</a></li>
		  <li><date>03.2024</date> Guest Lecture in Algorithmic Fairness Course, Cornell University</li>
		  <li><date>02.2024</date><a href="https://dsl.mit.edu/"> MIT Data Science Seminar Series</a></li>
		  <li><date>02.2024</date><a href="https://asset.seas.upenn.edu/event/himabindu-lakkaraju-harvard-university/"> UPenn Center for Safe, Explainable, and Trustworthy AI Seminar Series</a></li>
		  <li><date>02.2024</date><a href="https://ppai-workshop.github.io/"> AAAI Workshop on Privacy-Preserving Artificial Intelligence</a></li>
		  <li> <date>01.2024</date> NSF Workshop on Advanced Automated Systems, Contestability, and the Law </li>
		  <li> <date>10.2023</date> <a href="https://fds.yale.edu/calendar_event/machine-learning-workshop/">Yale and Google Joint Workshop on Theory and Practice of Foundation Models</a></li>
		  <li> <date>10.2023</date> <a href="https://sites.google.com/view/genai-risks-workshop-oct-2023/">Google, Stanford, and UW Madison Workshop on Securing the Future of GenAI</a></li>
		  <li> <date>10.2023</date> <a href="https://meetings.informs.org/wordpress/phoenix2023/">INFORMS Annual Meeting</a>
		  <li> <date>07.2023</date> <a href="https://sites.google.com/view/imlh2023/home?authuser=1">ICML Workshop on Interpretable ML in Healthcare</a></li>
		  <li> <date>07.2023</date> <a href="https://sites.google.com/view/counterfactuals-icml/home">ICML Workshop on Counterfactuals in Minds and Machines</a></li>
		  <li> <date>07.2023</date> <a href="https://sites.google.com/view/rss2023-safe-autonomy">RSS Workshop on Safe Autonomy</a></li>
		  <li> <date>05.2023</date> <a href="https://rtml-iclr2023.github.io">ICLR Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models</a></li>
		  <li> <date>05.2023</date> <a href="https://sites.google.com/view/rainscmu">Responsible AI Workshop at Carnegie Mellon University </a></li>
		  <li> <date>04.2023</date> Guest Lecture at <a href="https://safeai-lab.github.io/taiat-spring2022.html">Carnegie Mellon University</a></li>
		  <li> <date>04.2023</date> <a href="https://mind-machine.ucsb.edu/meetings">Mind and Machine Intelligence Summit</a>, UC Santa Barbara</li>
		  <li> <date>04.2023</date> <a href="https://india.acm.org/education/learning/bootcamp-apr2023">ACM India Bootcamp on Responsible Computing</a>
		  <li> <date>03.2023</date> <a href="https://www.mlim-cornell.club">Cornell University and Weill Cornell Medicine </a></li>
		  <li> <date>03.2023</date> Guest Lecture at <a href="https://niloufar.org/human-centered-ai-course/"> UC Berkeley </a></li>
		  <li> <date>03.2023</date> <a href="https://www.nasonline.org/programs/kavli-frontiers-of-science/">Kavli Frontiers of Science Symposium </a></li>
		  <li> <date>03.2023</date> <a href="https://info.cohere.ai/talking-language-ai-5">Cohere AI</a></li>
		  <li> <date>02.2023</date> Keynote at <a href="https://r2hcai.github.io/AAAI-23/index.html"> AAAI Workshop on Representation Learning for Responsible Human-Centric AI </a> </li>
		  <li> <date>02.2023</date> <a href="https://sites.google.com/view/dai-2023"> AAAI Workshop on Deployable AI </a> </li>
		  <li> <date>12.2022</date> <a href="https://cyber.harvard.edu/">Berkman Klein Center, Harvard University</a> </li>
		  <li> <date>11.2022</date> Keynote at <a href="https://sites.google.com/view/wiml2022/">Women in Machine Learning (WiML) Workshop</a> Co-located with NeurIPS, 2022 </li>
		  <li> <date>11.2022</date> <a href="https://ml4health.github.io/2022/">Machine Learning for Health (ML4H) Workshop</a> Co-located with NeurIPS, 2022 </li>
		  <li> <date>11.2022</date> <a href="https://simons.berkeley.edu/workshops/schedule/16936">Simons Institute (Berkeley) Workshop on Societal Considerations and Applications</a></li>
		  <li> <date>11.2022</date> <a href="https://ide.mit.edu/events/fall-2022-ide-lunch-seminar-series/">MIT Initiative on the Digital Economy (IDE) Seminar Series</a></li>
		  <li> <date>11.2022</date> <a href="https://www.hdsiconference.org/">Harvard Data Science Initiative's Annual Conference</a>
		  <li> <date>10.2022</date> <a href="https://eccv22-arow.github.io/">ECCV Workshop on Adversarial Robustness in the Real World</a> </li>
		  <li> <date>08.2022</date> <a href="https://aisafety.stanford.edu/">Stanford Center for AI Safety</a> </li>
		  <li> <date>08.2022</date> <a href="https://www.amazon.science/tag/alexa">Amazon Alexa</a> Rising Star Speaker Series </li>
		  <li> <date>06.2022</date> <a href="https://xai4cv.github.io/workshop">CVPR Workshop on Explainable AI for Computer Vision</a> </li>
		  <li> <date>05.2022</date> <a href="https://pair2struct-workshop.github.io/">ICLR Workshop on Privacy, Accountability, Interpretability, Robustness, Reasoning on Structured Data</a> </li>
		  <li> <date>05.2022</date> Keynote at <a href="https://aihealth.ischool.utexas.edu/AIHealthWWW2022/index.html">WWW Workshop on Explainable AI in Health</a> </li>
		  <li> <date>05.2022</date> Fiddler AI Fireside Chat </li>
		  <li> <date>04.2022</date> <a href="https://finreglab.org/artificial-intelligence-and-the-economy-charting-a-path-for-responsible-and-inclusive-ai-2">AI and the Economy</a> (U.S. Department of Commerce, National Institute of Standards and Technology, Stanford HAI, and the FinRegLab) </li>
		  <li> <date>04.2022</date> <a href="https://hai.stanford.edu/events/2022-hai-spring-conference-key-advances-artificial-intelligence">Stanford Human-Centered Artificial Intelligence (HAI) Conference</a> </li>
		  <li> <date>04.2022</date> <a href="https://digitaleconomy.stanford.edu/event/seminar-series-with-hima-lakkaraju/">Stanford Digital Econ Seminar</a> </li>
		  <li> <date>03.2022</date> University of Southern California </li>
		  <!-- <li> <date>12.2021</date> <a href="https://www.afciworkshop.org/">NeurIPS Workshop on Algorithmic Fairness through the Lens of Causality and Robustness</a> </li>
		  <li> <date>12.2021</date> <a href="https://xai4debugging.github.io/">NeurIPS Workshop on Explainable AI Approaches for Debugging and Diagnosis</a> </li>
		  <li> <date>12.2021</date> <a href="https://neurips.cc/virtual/2021/workshop/21835">NeurIPS Workshop on Human and Machine Decisions</a> </li>
		  <li> <date>12.2021</date> <a href="https://pinlabstechtalkdec21.splashthat.com/">Pinterest Tech Talks -- Distinguished Lecture</a> </li>
		  <li> <date>11.2021</date> Keynote at <a href="https://www.cikm2021.org/programme/keynote-speakers#towards-reliable-and-practicable-algorithmic-recourse">ACM Conference on Information and Knowledge Management</a> </li>
		  <li> <date>11.2021</date> <a href="https://www.nist.gov/news-events/events/2021/10/kicking-nist-ai-risk-management-framework"> NIST AI Risk Management Framework Workshop </a> </li>
		  <li> <date>11.2021</date> <a href="https://get.mccombs.utexas.edu/2021-catt-global-analytics-summit/#lp-pom-block-1164?utm_source=rss&utm_medium=rss&utm_campaign=catt-2021-global-analytics-summit-on-explainable-ai">Global Analytics Summit, University of Texas at Austin</a> </li>
		  <li>
			  <date>10.2021</date> <a href="https://www.fiddler.ai/fiddlers-explainable-ai-summit"> Explainable AI Summit, Fiddler.ai </a>
		  </li> 
		  <li>
			  <date>08.2021</date> <a href="https://www.youtube.com/watch?v=8Ym4oYTd8Fo"> Podcast on Explainability and Fairness in AI with Jay Shah </a>
		  </li> 
		  <li>
			  <date>08.2021</date> Keynote at <a href="https://sites.google.com/view/kdd-mlf-2020/">KDD Workshop on ML for Finance</a> 
		  </li>
		  <li> <date>07.2021</date> <a href="https://aiforgood.itu.int/event/trustworthy-ai-himabindu-lakkaraju/">AI for Good Summit organized by International Telecommunications Union & the United Nations </a> </li>
		  <li> 
			  <date>07.2021</date> <a href="https://sites.google.com/view/imlh2021/">ICML Workshop on Interpretable ML in Healthcare</a> 
		  </li>
		  <li>
			  <date>07.2021</date> <a href="http://www.neurosymbolic.org/events.html"> Neurosym Webinar Series, Jointly Organized by UPenn, MIT, Caltech, and Stanford </a>
		   <li> 
			  <date>06.2021</date> <a href="http://cvpr2021.thecvf.com/">CVPR Workshop on Responsible Computer Vision</a> 
		  </li>
		  <li>
			  <date>05.2021</date> Keynote at <a href="https://sites.google.com/view/rai-workshop/">ICLR Workshop on Responsible AI</a>
		  </li>
		  <li> 
			  <date>05.2021</date> <a href="https://www.cl.cam.ac.uk/research/ai/meetings/">University of Cambridge</a> 
		  </li>
		  <li>
			  <date>05.2021</date> Guest Lecture at <a href="https://exploreintrosems.stanford.edu/frosh/counterfactuals-science-what-ifs">Stanford University</a>
		  </li>
		  <li>
			  <date>04.2021</date> Invited Tutorial at <a href="https://www.chilconference.org/calendar.html#tab-tutorials">CHIL conference</a>
		  </li>
		  <li>
			  <date>04.2021</date> <a href="https://rss2workshop.github.io/">ASPLOS Workshop on Systems Architecture for Robust, Safe, and Resilient Software</a>
		  </li> 
		  <li>
			  <date>04.2021</date> <a href="https://personal-workshop.com/personal-mlsys-2021/">MLSys Workshop on Personalized Recommender Systems and Algorithms</a>
		  </li> 
		  <li>
			  <date>04.2021</date> <a href="https://www.sri.com/">SRI International</a>
		  </li>
		  <li>
			  <date>04.2021</date> Guest Lecture at <a href="https://projects.iq.harvard.edu/cs288/schedule">AI for Social Impact</a> course at Harvard University
		  </li>
		  <li> 
			  <date>02.2021</date> <a href="https://groups.cs.umass.edu/voicesofds/">Voices of Data Science, UMass Amherst</a> 
		  </li>
		  <li> 
			  <date>01.2021</date> <a href="https://www.cis.mpg.de/events/">Max Planck Symposium on Computing and Society</a> 
		  </li>
          <li>
		  <date>12.2020</date> Guest Lectures in <a href="https://www.cs.cmu.edu/~nihars/teaching/10715-Fa20/index.html">Advanced Machine Learning</a> and <a href="https://haiicmu.github.io/calendar/">Human-AI Interaction</a> Courses at <a href="https://www.cmu.edu/">Carnegie Mellon University</a>
		  
	  </li> -->
          </ul>
        </div>
      </div>
      </font>

      <div class="page-header" id="research"><h3>Research</h3></div>
	     <ul class="no-bullets">
		      <li>
			      <sup>*</sup> below indicates equal contribution
		      </li>
	      </ul>
	      <br />
     <h4>Selected Preprints</h4>
	    <ul class="no-bullets">
	     <li>
			      See <a href="https://scholar.google.com/citations?hl=en&user=oWid5PQAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar Page</a> for a full list of preprints
		      </li>
	    </ul>
	    <font size="3">
	      <br>
	      <ul>
		       <li>
			      <p>MedSafetyBench: Evaluating and Improving the Medical Safety of Large Language Models <br />
				      Tessa Han, Aounon Kumar, Chirag Agarwal, Himabindu Lakkaraju <br />
				      <a href="https://arxiv.org/pdf/2403.03744" class="btn btn-xs btn-default">pdf</a>
			      </p>
		      </li>
		     <li>
			      <p>Manipulating Large Language Models to Increase Product Visibility <br />
				      Aounon Kumar, Himabindu Lakkaraju <br />
				      <a href="https://arxiv.org/pdf/2404.07981" class="btn btn-xs btn-default">pdf</a>
				      Press: <a href="https://www.nytimes.com/2024/08/30/technology/ai-chatbot-chatgpt-manipulation.html" class="btn btn-xs btn-default">The New York Times</a> | <a href="https://towardsdatascience.com/can-recommendations-from-llms-be-manipulated-to-enhance-a-products-visibility-64c64fa9cd24" class="btn btn-xs btn-default">Towards Data Science</a>
			      </p>
		      </li>
		      <li>
			      <p>Interpreting CLIP with Sparse Linear Concept Embeddings (SpLiCE) <br />
				      Usha Bhalla, Alex Oesterling, Suraj Srinivas, Flavio Calmon, Himabindu Lakkaraju <br />
				      <a href="https://arxiv.org/abs/2402.10376" class="btn btn-xs btn-default">pdf</a>
			      </p>
		      </li>
		       <li>
			      <p>On the Hardness of Faithful Chain-of-Thought Reasoning in Large Language Models <br />
				      Sree Harsha Tanneru, Dan Ley, Chirag Agarwal, Himabindu Lakkaraju <br />
				      <a href="https://arxiv.org/abs/2406.10625" class="btn btn-xs btn-default">pdf</a>
				      Discussed in <a href="https://openai.com/index/openai-o1-system-card/">OpenAI o1 System Card</a>
			      </p>
		      </li>
		      <li>
			      <p>Manipulating Large Language Models to Increase Product Visibility <br />
				      Aounon Kumar, Himabindu Lakkaraju <br />
				      <a href="https://arxiv.org/pdf/2404.07981" class="btn btn-xs btn-default">pdf</a>
				      Press: <a href="https://www.nytimes.com/2024/08/30/technology/ai-chatbot-chatgpt-manipulation.html" class="btn btn-xs btn-default">The New York Times</a> | <a href="https://towardsdatascience.com/can-recommendations-from-llms-be-manipulated-to-enhance-a-products-visibility-64c64fa9cd24" class="btn btn-xs btn-default">Towards Data Science</a>
			      </p>
		      </li>
		      
		       <li>
			      <p>Are Large Language Models Post hoc Explainers? <br />
				      Nicholas Kroeger<sup>*</sup>, Dan Ley<sup>*</sup>, Satyapriya Krishna, Chirag Agarwal, Himabindu Lakkaraju <br />
				      <a href="https://arxiv.org/pdf/2310.05797.pdf" class="btn btn-xs btn-default">pdf</a>
			      </p>
		      </li>
	      </ul>
	    </font>
	    <br />
     <h4>Publications</h4>   
	<font size="3">
	      <br>
	      <ul>
		       <li>
			      <p>In-context Unlearning: Language Models as Few Shot Unlearners <br />
				      Martin Pawelczyk, Seth Neel, Himabindu Lakkaraju <br />
				      <i></i> International Conference on Machine Learning (ICML), 2024.<br />
				      <a href="https://arxiv.org/pdf/2310.07579.pdf" class="btn btn-xs btn-default">pdf</a>
			      </p>
		      </li>
		       <li>
			      <p>Understanding the Effects of Iterative Prompting on Truthfulness<br />
				      Satyapriya Krishna, Chirag Agarwal, Himabindu Lakkaraju <br />
				      <i></i> International Conference on Machine Learning (ICML), 2024.<br />
				      <a href="https://arxiv.org/pdf/2402.06625" class="btn btn-xs btn-default">pdf</a>
			      </p>
		      </li>
		      <li>
			      <p> Characterizing Data Point Vulnerability as Average-Case Robustness <br />
				      Tessa Han, Suraj Srinivas, Himabindu Lakkaraju <br />
				      <i></i> International Conference on Uncertainty in Artificial Intelligence (UAI), 2024.<br />
				      <a href="https://arxiv.org/pdf/2307.13885" class="btn btn-xs btn-default">pdf</a>
			      </p>
		      </li>
		     <li> <p> A Study on the Calibration of In-context Learning
 <br />
			      Hanlin Zhang, Yi-Fan Zhang, Yaodong Yu, Dhruv Madeka, Dean Foster, Eric Xing, Himabindu Lakkaraju, Sham Kakade<br />
			      <i></i> The North American Chapter of the Association for Computational Linguistics (NAACL), 2024.<br />
			      <a href="https://arxiv.org/pdf/2312.04021.pdf" class="btn btn-xs btn-default">pdf</a>	      
		      </p>
		      </li>
		      <li> <p> Investigating the Fairness of Large Language Models for Predictions on Tabular Data
 <br />
			      Yanchen Liu, Srishti Gautam, Jiaqi Ma, Himabindu Lakkaraju<br />
			      <i></i> The North American Chapter of the Association for Computational Linguistics (NAACL), 2024.<br />
			      <a href="https://arxiv.org/pdf/2310.14607.pdf" class="btn btn-xs btn-default">pdf</a>	      
		      </p>
		      </li>
		      <li>
		      <p> Quantifying Uncertainty in Natural Language Explanations of Large Language Models
 <br />
			      Sree Harsha Tanneru, Chirag Agarwal, Himabindu Lakkaraju<br />
			      <i></i> International Conference on Artificial Intelligence and Statistics (AISTATS), 2024.<br />
			      <font color="#cc0000"> Spotlight Presentation</font>, NeurIPS Workshop on Robustness of Few-shot and Zero-shot Learning in Foundation Models, 2023.<br />
		      	      <a href="https://arxiv.org/pdf/2311.03533.pdf" class="btn btn-xs btn-default">pdf</a>	      
		      </p>
	      </li>
		      <li>
		      <p> Fair Machine Unlearning: Data Removal while Mitigating Disparities
 <br />
			      Alex Oesterling, Jiaqi Ma, Flavio Calmon, Himabindu Lakkaraju<br />
			      <i></i> International Conference on Artificial Intelligence and Statistics (AISTATS), 2024.<br />
			      <a href="https://arxiv.org/pdf/2307.14754.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		      <li>
			      <p>The Disagreement Problem in Explainable Machine Learning: A Practitioner's Perspective <br />
				      Satyapriya Krishna<sup>*</sup>, Tessa Han<sup>*</sup>, Alex Gu, Javin Pombra, Shahin Jabbari, Steven Wu, Himabindu Lakkaraju <br />
				      <i></i> Transactions on Machine Learning Research (TMLR), 2024.<br />
				      Press: <a href="https://fortune.com/2022/03/22/ai-explainable-radiology-medicine-crisis-eye-on-ai/">Fortune Magazine</a>  <br />
				      <a href="https://arxiv.org/pdf/2202.01602.pdf" class="btn btn-xs btn-default">pdf</a>
			      </p>
		      </li>
		      <li>
			      <p>Certifying LLM Safety Against Adversarial Prompting <br />
				      Aounon Kumar, Chirag Agarwal, Suraj Srinivas, Aaron Li, Soheil Feizi, Himabindu Lakkaraju <br />
				       <i></i> Conference on Language Modeling (COLM), 2024.<br />
				      <a href="https://arxiv.org/pdf/2309.02705v2.pdf" class="btn btn-xs btn-default">pdf</a>
			      </p>
		      </li>
		      <li>
		      <p> TalkToModel: Explaining Machine Learning Models with Interactive Natural Language Conversations
 <br />
			      Dylan Slack, Satyapriya Krishna, Himabindu Lakkaraju<sup>*</sup>, Sameer Singh<sup>*</sup> <br />
			      <i></i> Nature Machine Intelligence, 2023.<br />
			      <font color="#cc0000"> Outstanding Paper Award Honorable Mention</font>, NeurIPS Workshop on Trustworthy and Socially Responsible ML, 2022. <br />
			      <a href="https://www.nature.com/articles/s42256-023-00692-8.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		      <li>
		      <p> Evaluating Explainability for Graph Neural Networks
 <br />
			      Chirag Agarwal, Owen Queen, Himabindu Lakkaraju, Marinka Zitnik <br />
			      <i></i> Nature Scientific Data, 2023.<br />
			      <a href="https://arxiv.org/pdf/2208.09339.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		      <li>
		      <p> Post Hoc Explanations of Language Models Can Improve Language Models
 <br />
			      Satyapriya Krishna, Jiaqi Ma, Dylan Slack, Asma Ghandeharioun, Sameer Singh, Himabindu Lakkaraju <br />
			      <i></i> Advances in Neural Information Processing Systems (NeurIPS), 2023.<br />
			      <a href="https://arxiv.org/pdf/2305.11426.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		      <li>
		      <p> Verifiable Feature Attributions: A Bridge between Post Hoc Explainability and Inherent Interpretability
 <br />
			      Usha Bhalla<sup>*</sup>, Suraj Srinivas<sup>*</sup>, Himabindu Lakkaraju <br />
			      <i></i> Advances in Neural Information Processing Systems (NeurIPS), 2023.<br />
			      <a href="https://arxiv.org/pdf/2307.15007.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		      <li>
		      <p> Which Models have Perceptually-Aligned Gradients? An Explanation via Off-Manifold Robustness
 <br />
			      Suraj Srinivas<sup>*</sup>, Sebastian Bordt<sup>*</sup>, Himabindu Lakkaraju <br />
			      <i></i> Advances in Neural Information Processing Systems (NeurIPS), 2023.<br />
			      <font color="#cc0000"> Spotlight Presentation [Top 3%] </font> <br />
			      <a href="https://arxiv.org/pdf/2305.19101.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		      <li>
		      <p> M<sup>4</sup>: A Unified XAI Benchmark for Faithfulness Evaluation of Feature Attribution Methods across Metrics, Modalities, and Models
 <br />
			      Xuhong Li, Mengnan Du, Jiamin Chen, Yekun Chai, Himabindu Lakkaraju, Haoyi Xiong <br />
			      <i></i> Advances in Neural Information Processing Systems (NeurIPS), 2023.<br />
			      <!-- <a href="https://arxiv.org/pdf/2305.19101.pdf" class="btn btn-xs btn-default">pdf</a> -->
		      </p>
	      </li>   
		      <li>
		      <p> When Does Uncertainty Matter?: Understanding the Impact of Predictive Uncertainty in ML Assisted Decision Making
 <br />
			      Sean McGrath, Parth Mehta, Alexandra Zytek, Isaac Lage, Himabindu Lakkaraju <br />
			      <i></i> Transactions on Machine Learning Research (TMLR), 2023.<br />
			      <a href="https://arxiv.org/pdf/2011.06167.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		      
		       <li>
		      <p> Towards Bridging the Gaps between the Right to Explanation and the Right to be Forgotten
 <br />
			      Satyapriya Krishna<sup>*</sup>, Jiaqi Ma<sup>*</sup>, Himabindu Lakkaraju <br />
			      <i></i> International Conference on Machine Learning (ICML), 2023<br />
			      <a href="https://arxiv.org/pdf/2302.04288.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		      <li>
		      <p> On the Impact of Actionable Explanations on Social Segregation
 <br />
			      Ruijiang Gao, Himabindu Lakkaraju <br />
			      <i></i> International Conference on Machine Learning (ICML), 2023<br />
			      <a href="https://proceedings.mlr.press/v202/gao23d/gao23d.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		       <li>
		      <p> On Minimizing the Impact of Dataset Shifts on Actionable Explanations
 <br />
			      Anna Meyer<sup>*</sup>, Dan Ley<sup>*</sup>, Suraj Srinivas, Himabindu Lakkaraju <br />
			      <i></i> Conference on Uncertainty in Artificial Intelligence (UAI), 2023<br />
			      <font color="#cc0000"> Oral Presentation [Top 5%] </font> <br />
			      <a href="https://arxiv.org/pdf/2306.06716.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		      <li>
		      <p> Probabilistically Robust Recourse: Navigating the Trade-offs between Costs and Robustness in Algorithmic Recourse
 <br />
			      Martin Pawelczyk, Teresa Datta, Johannes van-den-Heuvel, Gjergji Kasneci, Himabindu Lakkaraju <br />
			      <i></i> International Conference on Learning Representations (ICLR), 2023<br />
			      <a href="https://arxiv.org/pdf/2203.06768.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		      <li>
		      <p> On the Privacy Risks of Algorithmic Recourse
 <br />
			      Martin Pawelczyk, Himabindu Lakkaraju, Seth Neel <br />
			      <i></i> International Conference on Artificial Intelligence and Statistics (AISTATS), 2023<br />
			      <a href="https://arxiv.org/pdf/2211.05427.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>   
		      <li>
		      <p> Which Explanation Should I Choose? A Function Approximation Perspective to Characterizing Post hoc Explanations
 <br />
			      Tessa Han, Suraj Srinivas, Himabindu Lakkaraju <br />
			      <i></i> Advances in Neural Information Processing Systems (NeurIPS), 2022.<br />
			      <font color="#cc0000">Best Paper Award</font>, ICML Workshop on Interpretable Machine Learning in Healthcare, 2022. <br />
			      <a href="https://arxiv.org/pdf/2206.01254.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		      <li>
		      <p> Flatten the Curve: Efficiently Training Low-Curvature Neural Networks <br />
			      Suraj Srinivas, Kyle Matoba, Himabindu Lakkaraju, Francois Fleuret <br />
			      <i></i> Advances in Neural Information Processing Systems (NeurIPS), 2022.<br />
			      <a href="https://arxiv.org/pdf/2206.07144.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		         <li>
		      <p> OpenXAI: Towards a Transparent Evaluation of Model Explanations <br />
			      Chirag Agarwal, Satyapriya Krishna, Eshika Saxena, Martin Pawelczyk, Nari Johnson, Isha Puri, Marinka Zitnik, Himabindu Lakkaraju <br />
			      <i></i> Advances in Neural Information Processing Systems (NeurIPS), 2022.<br />
			      <a href="https://arxiv.org/pdf/2206.11104.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
		      <li>
		      <p> Data Poisoning Attacks on Off-Policy Evaluation Methods <br />
			      Elita Lobo, Harvineet Singh, Marek Petrik, Cynthia Rudin, Himabindu Lakkaraju <br />
			      <i></i> Conference on Uncertainty in Artificial Intelligence (UAI), 2022.<br />
			      <font color="#cc0000"> Oral Presentation [Top 5%] </font> <br />
			      <a href="https://openreview.net/pdf?id=BgbgH_Ls5lc" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
              <li>
		      <p> Exploring Counterfactual Explanations Through the Lens of Adversarial Examples: A Theoretical and Empirical Analysis. <br />
			      Martin Pawelczyk, Chirag Agarwal, Shalmali Joshi, Sohini Upadhyay, Himabindu Lakkaraju <br />
			      <i></i> International Conference on Artificial Intelligence and Statistics (AISTATS), 2022.<br />
			      <a href="https://arxiv.org/pdf/2106.09992.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	      <li>
		      <p> Probing GNN Explainers: A Rigorous Theoretical and Empirical Analysis of GNN Explanation Methods. <br />
			      Chirag Agarwal, Marinka Zitnik, Himabindu Lakkaraju <br />
			      <i></i> International Conference on Artificial Intelligence and Statistics (AISTATS), 2022.<br />
			      <a href="https://arxiv.org/pdf/2106.09078.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	      <li>
		      <p> Fairness via Explanation Quality: Evaluating Disparities in the Quality of Post hoc Explanations. <br />
			      Jessica Dai, Sohini Upadhyay, Ulrich Aivodji, Stephen Bach, Himabindu Lakkaraju<br />
			      <i></i> AAAI/ACM Conference on AI, Society, and Ethics (AIES), 2022.<br />
			      <a href="https://arxiv.org/pdf/2205.07277.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>    
	      </li>
	      <li>
		      <p> Towards Robust Off-Policy Evaluation via Human Inputs. <br />
			      Harvineet Singh, Shalmali Joshi, Finale Doshi-Velez, Himabindu Lakkaraju<br />
			      <i></i> AAAI/ACM Conference on AI, Society, and Ethics (AIES), 2022.<br />
			      <a href="https://dl.acm.org/doi/10.1145/3514094.3534198" class="btn btn-xs btn-default">pdf</a>
		      </p>  
	      </li>
	      <li>
		      <p> A Human-Centric Take on Model Monitoring. <br />
			      Murtuza N Shergadwala, Himabindu Lakkaraju, Krishnaram Kenthapadi <br />
			      <i></i> AAAI Conference on Human Computation and Crowdsourcing (HCOMP), 2022.<br />
			      <a href="https://arxiv.org/pdf/2206.02868.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>  
	      </li>
	      <li>
		      <p> Towards the Unification and Robustness of Post hoc Explanation Methods. <br />
			      Sushant Agarwal, Shahin Jabbari, Chirag Agarwal<sup>*</sup>, Sohini Upadhyay<sup>*</sup>, Steven Wu, Himabindu Lakkaraju <br />
			      <i></i>Symposium on Foundations of Responsible Computing (FORC), 2022. <br />
			      <a href="https://arxiv.org/pdf/2102.10618.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>    
	      </li>
	      <li>
		      <p> Towards Robust and Reliable Algorithmic Recourse. <br />
			      Sohini Upadhyay<sup>*</sup>, Shalmali Joshi<sup>*</sup>, Himabindu Lakkaraju <br />
			      <i></i>Advances in Neural Information Processing Systems (NeurIPS), 2021.<br />
			      <font color="#cc0000">Best Paper Runner Up</font>, ICML Workshop on Algorithmic Recourse, 2021. <br />
                      	      <a href="https://arxiv.org/pdf/2102.13620.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	     
	      <li>
		      <p> Reliable Post hoc Explanations: Modeling Uncertainty in Explainability. <br />
			      Dylan Slack, Sophie Hilgard, Sameer Singh, Himabindu Lakkaraju <br />
			      <i></i>Advances in Neural Information Processing Systems (NeurIPS), 2021.<br />
                      	      <a href="https://arxiv.org/pdf/2008.05030.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>  
	      <li>
		      <p> Counterfactual Explanations Can Be Manipulated <br />
			      Dylan Slack, Sophie Hilgard, Himabindu Lakkaraju, Sameer Singh <br />
			      <i></i>Advances in Neural Information Processing Systems (NeurIPS), 2021.<br />
                      	      <a href="https://arxiv.org/pdf/2106.02666.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	      <li>
		      <p> Learning Models for Algorithmic Recourse <br />
			      Alexis Ross, Himabindu Lakkaraju, Osbert Bastani <br />
			      <i></i>Advances in Neural Information Processing Systems (NeurIPS), 2021.<br />
                      	      <a href="https://arxiv.org/pdf/2011.06146.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	      <li> 
		      <p> Towards the Unification and Robustness of Perturbation and Gradient Based Explanations. <br />
			      Sushant Agarwal, Shahin Jabbari, Chirag Agarwal<sup>*</sup>, Sohini Upadhyay<sup>*</sup>, Steven Wu, Himabindu Lakkaraju <br />
			      <i></i>International Conference on Machine Learning (ICML), 2021.<br />
			      <font color="#cc0000"> Spotlight Presentation </font> <br />
			      <a href="https://arxiv.org/pdf/2102.10618.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	      <li> 
		      <p> Towards a Unified Framework for Fair and Stable Graph Representation Learning. <br />
			      Chirag Agarwal, Himabindu Lakkaraju, Marinka Zitnik <br />
			      <i></i>Conference on Uncertainty in Artificial Intelligence (UAI), 2021.<br />
			      <a href="https://arxiv.org/pdf/2102.13186.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	      <li> 
		      <p> Fair influence maximization: A welfare optimization approach. <br />
			      Aida Rahmattalabi, Shahin Jabbari, Himabindu Lakkaraju, Phebe Vayanos, Eric Rice, Milind Tambe <br />
			      <i></i> AAAI International Conference on Artificial Intelligence (AAAI), 2021.<br />
			      <a href="https://arxiv.org/pdf/2006.07906.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
              <li> 
		      <p> Does Fair Ranking Improve Minority Outcomes? Understanding the Interplay of Human and Algorithmic Biases in Online Hiring. <br />
			      Tom Suhr, Sophie Hilgard, Himabindu Lakkaraju <br />
			      <i></i>AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES), 2021.<br />
			      <a href="https://arxiv.org/pdf/2012.00423.pdf" class="btn btn-xs btn-default">pdf</a>
		      </p>
	      </li>
	  <li>
              <p> Beyond Individualized Recourse: Interpretable and Interactive Summaries of Actionable Recourses <br />
                  Kaivalya Rawal and Himabindu Lakkaraju. <br />
      <i></i>Advances in Neural Information Processing Systems (NeurIPS), 2020.<br />
                  <a href="https://arxiv.org/abs/2009.07165" class="btn btn-xs btn-default">pdf</a>
              </p>
          </li>
	  <li>
              <p> Incorporating Interpretable Output Constraints in Bayesian Neural Networks <br />
                  Wanqian Yang, Lars Lorch, Moritz Gaule, Himabindu Lakkaraju, Finale Doshi-Velez. <br />
      <i></i>Advances in Neural Information Processing Systems (NeurIPS), 2020.<br />
		  <font color="#cc0000"> Spotlight Presentation [Top 3%] </font> <br />
                  <a href="https://arxiv.org/pdf/2010.10969.pdf" class="btn btn-xs btn-default">pdf</a> <br />
              </p>
	  </li>
          <li>
              <p> Robust and Stable Black Box Explanations. <br />
                  Himabindu Lakkaraju, Nino Arsov, Osbert Bastani. <br />
      <i></i>International Conference on Machine Learning (ICML), 2020.<br />
                  <a href="https://proceedings.icml.cc/static/paper_files/icml/2020/5945-Paper.pdf" class="btn btn-xs btn-default">pdf</a>
              </p>
          </li>
          <li>
              <p> Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods. <br />
                  Dylan Slack, Sophie Hilgard, Emily Jia, Sameer Singh, Himabindu Lakkaraju. <br />
		  <i></i>AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES), 2020.<br />
		  <font color="#cc0000"> Oral Presentation </font> <br />
                  <a href="https://arxiv.org/pdf/1911.02508.pdf" class="btn btn-xs btn-default">pdf</a> <br />
		  Press: <a href="https://blog.deeplearning.ai/blog/the-batch-sony-goes-ai-intels-gpu-killers-transformer-networks-in-disguise-malicious-models-fool-bias-detection">deeplearning.ai</a> | 
		      <a href="https://hbr.org/2019/12/the-ai-transparency-paradox">Harvard Business Review</a>
              </p>
          </li>
	  <li>
              <p> "How do I fool you?": Manipulating User Trust via Misleading Black Box Explanations. <br />
                  Himabindu Lakkaraju, Osbert Bastani. <br />
		  <i></i>AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES), 2020.<br />
		  <font color="#cc0000"> Oral Presentation </font> <br />
                  <a href="https://arxiv.org/pdf/1911.06473.pdf" class="btn btn-xs btn-default">pdf</a>
	      </p>  
          </li>
        <li>
        <p>Faithful and Customizable Explanations of Black Box Models.<br />
           Himabindu Lakkaraju, Ece Kamar, Rich Carauna, Jure Leskovec.<br />
           <i></i>AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES), 2019.<br />
           <font color="#cc0000"> Oral Presentation </font> <br />
           <a href="./customizable.pdf" class="btn btn-xs btn-default">pdf</a>
        </p>
        </li>
	<li><p>Human Decisions and Machine Predictions.<br />
	    Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, Sendhil Mullainathan.<br />
	    <i>Quarterly Journal of Economics (QJE)</i>, 2018.<br />	
	    <heavy>Featured in MIT Technology Review, Harvard Business Review, The New York Times,</heavy><br />   
	    <heavy>and as Research Spotlight on National Bureau of Economics front page</heavy>.<br />   
	    <a href="https://academic.oup.com/qje/article/doi/10.1093/qje/qjx032/4095198/Human-Decisions-and-Machine-Predictions#" class="btn btn-xs btn-default">pdf</a>  
	</p></li>
	
        <li><p>The Selective Labels Problem: Evaluating Algorithmic Predictions in the Presence of Unobservables.<br />
	    Himabindu Lakkaraju, Jon Kleinberg, Jure Leskovec, Jens Ludwig, Sendhil Mullainathan. <br />
	    <i>ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</i>, 2017. <br/>
	    <font color="#cc0000"> Oral Presentation </font> <br />
	    <a href="http://cs.stanford.edu/~jure/pubs/contraction-kdd17.pdf" class="btn btn-xs btn-default">pdf</a>
	</p></li>

        <li><p>Learning Cost-Effective and Interpretable Treatment Regimes.<br />
            Himabindu Lakkaraju, Cynthia Rudin.<br />
	    <i>International Conference on Artificial Intelligence and Statistics (AISTATS)</i>, 2017.<br />
	    <font color="#cc0000">INFORMS Data Mining Best Paper Award </font>.<br /> 
	    <heavy>Invited Talk at INFORMS Annual Meeting</heavy>.<br />   
            <a href="https://arxiv.org/abs/1610.06972" class="btn btn-xs btn-default">pdf</a>
            
        </p></li>
	
        <li><p>Identifying Unknown Unknowns in the Open World: Representations and Policies for Guided Exploration.<br />
            Himabindu Lakkaraju, Ece Kamar, Rich Caruana, Eric Horvitz.<br />
            <i>AAAI Conference on Artificial Intelligence (AAAI)</i>, 2017.<br />
            <heavy>Featured in Bloomberg Technology</heavy>.<br />
            <a href="https://arxiv.org/abs/1610.09064" class="btn btn-xs btn-default">pdf</a>
            
        </p></li>
	
        <li><p> Interpretable and Explorable Approximations of Black Box Models.<br />
            Himabindu Lakkaraju, Ece Kamar, Rich Caruana, Jure Leskovec.<br />
            <i>KDD Workshop on Fairness, Accountability, and Transparency in Machine Learning (FAT ML)</i>, 2017.<br />
            <heavy>Invited Talk at INFORMS Annual Meeting</heavy>.<br />   
            <a href="https://arxiv.org/abs/1707.01154" class="btn btn-xs btn-default">pdf</a>
        </p></li>
        
        <li><p>Confusions over Time: An Interpretable Bayesian Model to Characterize Trends in Decision Making.<br />
            Himabindu Lakkaraju, Jure Leskovec.<br />
            <i>Advances in Neural Information Processing Systems (NIPS)</i>, 2016. <br/>
            <a href="https://snap.stanford.edu/hima/paper-temporal-confusions.pdf" class="btn btn-xs btn-default">pdf</a>
        </p></li>
        
        <li><p>Interpretable Decision Sets: A Joint Framework for Description and Prediction.<br />
            Himabindu Lakkaraju, Stephen H. Bach, Jure Leskovec. <br />
            <i>ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</i>, 2016. <br/>
            <heavy>Invited Talk at INFORMS Annual Meeting</heavy>.<br />   
            <a href="https://cs.stanford.edu/people/jure/pubs/interpretable-kdd16.pdf" class="btn btn-xs btn-default">pdf</a>	  
        </p></li>
        
        <li><p> Mining Big Data to Extract Patterns and Predict Real-Life Outcomes. <br />
            Michal Kosinki, Yilun Wang, Himabindu Lakkaraju, Jure Leskovec.<br />
            <i>Psychological Methods</i>, 2016.<br />
            <a href="http://mypersonality.org/wiki/lib/exe/fetch.php?media=psychological_methods.pdf" class="btn btn-xs btn-default">pdf</a>  
        </p></li>
        
        <li><p>Learning Cost-Effective and Interpretable Regimes for Treatment Recommendation.<br />
            Himabindu Lakkaraju, Cynthia Rudin.<br />
            <i>NIPS Workshop on Interpretable Machine Learning in Complex Systems</i>, 2016.<br />
            <a href="https://arxiv.org/pdf/1611.07663.pdf" class="btn btn-xs btn-default">pdf</a>
        </p></li>
        
        <li><p>Learning Cost-Effective and Interpretable Treatment Regimes for Judicial Bail Decisions. <br />
	    Himabindu Lakkaraju, Cynthia Rudin. <br />
	    <i>NIPS Symposium on Machine Learning and the Law</i>, 2016.<br />
	    <a href="http://www.mlandthelaw.org/papers/lakkaraju.pdf" class="btn btn-xs btn-default">pdf</a>	  
	</p></li>

	<li><p>Discovering Unknown Unknowns of Predictive Models.<br />
	    Himabindu Lakkaraju, Ece Kamar, Rich Caruana, Eric Horvitz.<br />
	    <i>NIPS Workshop on Reliable Machine Learning in the Wild</i>, 2016.<br />
	    <a href="http://web.stanford.edu/~himalv/unknownunknownsws.pdf" class="btn btn-xs btn-default">pdf</a>
	</p></li>

	<li><p>A Machine Learning Framework to Identify Students at Risk of Adverse Academic Outcomes. <br />
	    Himabindu Lakkaraju, Everaldo Aguiar, Carl Shan, David Miller, Nasir Bhanpuri, Rayid Ghani. <br />
	    <i>ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</i>, 2015.<br />
            <font color="#cc0000"> Oral Presentation </font> <br />
	    <a href="http://dssg.uchicago.edu/papers/montgomery_education.pdf" class="btn btn-xs btn-default">pdf</a>	
	</p></li>

	<li><p>A Bayesian Framework for Modeling Human Evaluations. <br />
	    Himabindu Lakkaraju, Jure Leskovec, Jon Kleinberg, Sendhil Mullainathan. <br />
	    <i>SIAM International Conference on Data Mining (SDM) </i>, 2015.<br />
	   <font color="#cc0000"> Oral Presentation </font> <br />
	    <a href="http://cs.stanford.edu/people/jure/pubs/evaluations-sdm15.pdf" class="btn btn-xs btn-default">pdf</a>  
	</p></li>

	<li><p>Who, When, and Why: A Machine Learning Approach to Prioritizing Students at Risk of not Graduating High School on Time.<br />
	    Everaldo Aguiar, Himabindu Lakkaraju, Nasir Bhanpuri, David Miller, Ben Yuhas, Kecia Addison, Rayid Ghani.
<br />
	    <i>Learning Analytics and Knowledge Conference (LAK)</i>, 2015.<br />
	    <a href="http://dl.acm.org/citation.cfm?id=2723619" class="btn btn-xs btn-default">pdf</a>
	</p></li>

	<!-- <li><p>Aspect Specific Sentiment Analysis using Hierarchical Deep Learning.<br />
	    Himabindu Lakkaraju, Richard Socher, Chris Manning.<br />
	    <i>NIPS Workshop on Deep Learning and Representation Learning</i>, 2014.<br />
	    <a href="http://www.dlworkshop.org/58.pdf?attredirects=0" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>

	<li><p>Using Big Data to Improve Social Policy.<br />
	    Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, Sendhil Mullainathan.<br />
	    <i>NBER Economics of Crime Working Group</i>, 2014.<br />
	    <a href="https://academic.oup.com/qje/article/doi/10.1093/qje/qjx032/4095198/Human-Decisions-and-Machine-Predictions#" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li> -->

	<li><p>What's in a name ? Understanding the Interplay Between Titles, Content, and Communities in Social Media.<br />
	    Himabindu Lakkaraju, Julian McAuley, Jure Leskovec. <br />
	    <i>International AAAI Conference on Weblogs and Social Media (ICWSM)</i>, 2013.<br />
	    <font color="#cc0000"> Oral Presentation </font> <br />
	    <heavy>Featured in Time, Forbes, Phys.Org, Business Insider</heavy>.<br />
	    <a href="https://sites.google.com/site/himabindulv/papers/ICWSM2013.pdf?attredirects=0" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>

	<li><p>Dynamic Multi-Relational Chinese Restaurant Process for Analyzing Influences on Users in Social Media.<br />
	    Himabindu Lakkaraju, Indrajit Bhattacharya, Chiranjib Bhattacharyya.<br />
	    <i>IEEE International Conference on Data Mining (ICDM)</i>, 2012.<br />
	    <font color="#cc0000"> Oral Presentation </font> <br />
	    <a href="http://arxiv.org/abs/1205.1456" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>
	<li><p>TEM: a novel perspective to modeling content on microblogs.<br />
	    Himabindu Lakkaraju, Hyung-Il Ahn.<br />
	    <i>International World Wide Web Conference (WWW), short paper</i>, 2012.<br />
	    <a href="http://www2012.wwwconference.org/proceedings/companion/p553.pdf" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>
	<li><p>Exploiting Coherence for the Simultaneous Discovery of Latent Facets and associated Sentiments.<br />
	    Himabindu Lakkaraju, Chiranjib Bhattacharyya, Indrajit Bhattacharya, Srujana Merugu.<br />
	    <i>SIAM International Conference on Data Mining (SDM)</i>, 2011.<br />
	    <font color="#cc0000">Best Paper Award</font>.<br />
	    <a href="https://sites.google.com/site/himabindulv/papers/324.pdf?attredirects=0" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>
	<li><p>Attention prediction on social media brand pages.<br />
	    Himabindu Lakkaraju, Jitendra Ajmera.<br />
	    <i>ACM Conference on Information and Knowledge Management (CIKM)</i>, 2011.<br />
	    <a href="https://sites.google.com/site/himabindulv/papers/cikm0226-lakkaraju.pdf?attredirects=0" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>
	<li><p>Smart news feeds for social networks using scalable joint latent factor models.<br />
	    Himabindu Lakkaraju, Angshu Rai, Srujana Merugu.<br />
	    <i>International World Wide Web Conference (WWW), short paper</i>, 2011.<br />
	    <a href="https://sites.google.com/site/himabindulv/papers/smartnewsfeeds1.pdf?attredirects=0" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>
	<!--<li><p>A Non Parametric Theme Event Topic Model for Characterizing Microblogs.<br />
	    Himabindu Lakkaraju, Hyung-Il Ahn. <br />
	    <i>NIPS Workshop on Computational Social Science and the Wisdom of Crowds</i>, 2011.<br />
	    <a href="https://sites.google.com/site/himabindulv/papers/themeevent-final.pdf?attredirects=0" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>
	<li><p>Unified Modeling of User Activities on Social Networking Sites.<br />
	    Himabindu Lakkaraju, Angshu Rai. <br />
	    <i>NIPS Workshop on Computational Social Science and the Wisdom of Crowds</i>, 2011.<br />
	    <a href="https://sites.google.com/site/himabindulv/papers/unifiedmodeling-final.pdf?attredirects=0" class="btn btn-xs btn-default">pdf</a>  	  
	</p></li>-->
      </ul>
      </font>
      <br />
      <h4>Patents</h4>
      <br>
      <font size="3">
      <ul>
	<li><p>Extraction and Grouping of Feature Words.<br />
	    Himabindu Lakkaraju, Chiranjib Bhattacharyya, Sunil Aravindam, Kaushik Nath.<br />
	    US8484228<br />
	</p></li>
	<li><p>Enhancing knowledge bases using rich social media.<br />
	    Jitendra Ajmera, Shantanu Ravindra Godbole, Himabindu Lakkaraju, Bernard Andrew Roden, Ashish Verma. <br />
	    US20130224714<br />
	</p></li>
      </ul>	 
      </font>
		
    <div class="page-header" id="students"> <h3>Advising</h3> </div>
		
    		<p>I am very fortunate to be working with the following core group of students, interns, postdocs, and research affiliates</p>
		<p>
		<ul>
			<li style="font-weight:normal">Suraj Srinivas (Postdoc, Harvard University)</li>
			<li style="font-weight:normal">Chirag Agarwal (Postdoc, Harvard University)</li>
			<li style="font-weight:normal">Martin Pawelczyk (Postdoc, Harvard University); Co-advised with Seth Neel</li>
			<li style="font-weight:normal">Aounon Kumar (Postdoc, Harvard University)</li>
			<li style="font-weight:normal">Tessa Han (PhD Student, Harvard University)</li>
			<li style="font-weight:normal">Satyapriya Krishna (PhD Student, Harvard University)</li>
			<li style="font-weight:normal">Usha Bhalla (PhD Student, Harvard University) </li>
			<li style="font-weight:normal">Dan Ley (PhD Student, Harvard University)</li>
			<li style="font-weight:normal">Alex Oesterling (PhD Student, Harvard University); Co-advised with Flavio Calmon </li>
			<li style="font-weight:normal">Paul Hamilton (PhD Student, Harvard University)</li>
			<li style="font-weight:normal">Yanchen Liu (Masters Student, Harvard University)</li>
			<li style="font-weight:normal">Sree Harsha Tanneru (Masters Student, Harvard University)</li>
			<li style="font-weight:normal">Nikhil Nayak (Masters Student, Harvard University)</li>
			<li style="font-weight:normal">Aaron Li (Masters Student, Harvard University)</li>
			<li style="font-weight:normal">Catherine Huang (Undergrad, Harvard University)</li>
			<li style="font-weight:normal">Charu Badrinath (Undergrad, Harvard University)</li>
			<li style="font-weight:normal">Christina Xiao (Undergrad, Harvard University)</li>
			<br>
			
				
		</ul>
		</p>
	    	<p> <b>Alumni</b> (Past Advisees, Close Collaborators, and Visitors): </p>
		<p>
	    	<ul>
			<li style="font-weight:normal">Jiaqi Ma (Postdoc, Harvard University --> Assistant Professor, UIUC)</li>
			<li style="font-weight:normal">Dylan Slack (PhD Student, UC Irvine --> Research Scientist, Scale AI)</li>
			<li style="font-weight:normal">Alexis Ross (Undergraduate Student, Harvard University -- Winner of Hoopes Prize for Best Undergrad Thesis --> PhD Student, MIT EECS)</li>
			<li style="font-weight:normal">Isha Puri (Undergraduate Student, Harvard University --> PhD Student, MIT EECS) </li>
			<li style="font-weight:normal">Jessica Dai (Undergraduate Student, Brown University --> PhD Student, UC Berkeley EECS) </li>	
			<li style="font-weight:normal">Aditya Karan (Masters Student, Harvard University --> PhD Student, UIUC CS)</li>
			<li style="font-weight:normal">Kaivalya Rawal (Masters Student, Harvard University --> Fiddler AI)</li>
			<li style="font-weight:normal">Ethan Kim (Undergraduate Student, Harvard University --> Cyndx) </li>
			<li style="font-weight:normal">Eshika Saxena (Undergraduate Student, Harvard University) </li>
			<br>
			<li style="font-weight:normal">Sophie Hilgard (PhD Student, Harvard University --> Research Scientist, Twitter) </li>
			<li style="font-weight:normal">Sushant Agarwal (Masters Student, University of Waterloo --> PhD Student, Northeastern University) </li>
			<br>
			<li style="font-weight:normal">Harvineet Singh (PhD Student, New York University; Research Intern, Harvard University --> Postdoc UCSF/UC Berkeley) </li>
			<li style="font-weight:normal">Tom Suhr (MS Student, TU Berlin; Research Fellow, Harvard University --> PhD Student, Max Planck Institute) </li>
			<li style="font-weight:normal">Elita Lobo (PhD Student, UMass Amherst; Research Intern, Harvard University) </li>
			<li style="font-weight:normal">Anna Meyer (PhD Student, University of Wisconsin; Research Intern, Harvard University)</li>
			<li style="font-weight:normal">Ruijiang Gao (PhD Student, University of Texas at Austin; Research Intern, Harvard University)</li>
			<li style="font-weight:normal">Vishwali Mhasawade (PhD Student, New York University; Research Intern, Harvard University)</li>
			<li style="font-weight:normal">Nick Kroeger (PhD Student, University of Florida; Research Intern, Harvard University) </li>
			<li style="font-weight:normal">Chhavi Yadav (PhD Student, UC San Diego; Research Intern, Harvard University)</li>
			<li style="font-weight:normal">Davor Ljubenkov (Fullbright Scholar; Research Fellow, Harvard University)</li>
			
			
		</ul>
		</p>
    <div class="page-header" id="teaching"><h3>Teaching</h3></div>
     <font size="3">
	     
      <ul>
	<li><p> <a href="https://www.hbs.edu/mba/academic-experience/curriculum/Pages/required-curriculum.aspx">Introduction to Data Science and Machine Learning</a><br/>
	        Instructor <br />
		<i>Harvard University</i>, Fall 2020 - 2023.<br />
	</p></li>
	<li><p> <a href="https://interpretable-ml-class.github.io/">Explainable AI: From Simple Predictors to Complex Generative Models</a><br/>
	        Instructor <br />
		<i>Harvard University</i>, Fall 2019, Spring 2021, Spring 2023.<br />
	</p></li>
	<li><p>Introduction to Data Science<br />
	    Guest Lecture<br />
	    <i>Stanford Law School</i>, 2016.<br />	 
	</p></li>
	<li><p>Probability with Mathemagic<br />
	    Co-Instructor<br />
	    <i>Stanford Splash Initiative for High School Students</i>, 2016.<br />	 
	</p></li>
	<li><p>Mining Massive Datasets Course<br />
	    Teaching Assistant<br />
	    <i>Stanford Computer Science</i>, 2016.<br />	 
	</p></li>
	<li><p>Submodular Optimization<br />
	    Guest Lecture<br />
	    <i>Mining Massive Datasets Course, Stanford</i>, 2016.<br />	 
	</p></li>
	<li><p>Introduction to Python Programming<br />
	    Co-Instructor<br />
	    <i>Stanford Girls Teaching Girls to Code Initiative for High School Students</i>, 2015.<br />	 
	</p></li>
	<li><p>Mathematics and Science<br />
	    Tutor<br />
	    <i>Dreamcatchers Non-Profit Organization, Palo Alto</i>, 2015.<br />	 
	</p></li>
	<li><p>Social and Information Network Analysis Course<br />
	    Head Teaching Assistant<br />
	    <i>Stanford Computer Science</i>, 2014.<br />	 
	</p></li>
	<li><p>Machine Learning Course<br />
	    Teaching Assistant<br />
	    <i>Indian Institute of Science</i>, 2010.<br />	 
	</p></li>
	<li><p>English and Mathematics<br />
	    Tutor<br />
	    <i>UNICEF's Teach India Initiative</i>, 2008 - 2010.<br />	 
	</p></li>
	</ul>
	</font>
    </div> <!-- /container -->


    <!-- Bootstrap core JavaScript
	 ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')</script>
      <script src="js/bootstrap.min.js"></script>
      <script src="js/docs.min.js"></script>
      <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
      <script src="js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>
